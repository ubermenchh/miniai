{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ee1f28-8589-4b88-8eae-ccfe1b02c534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|default_exp conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedf0c8-783f-48f6-909b-12fb083e46a8",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "635efb23-1ce0-490a-9650-1c6a028b086e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import default_collate\n",
    "from typing import Mapping\n",
    "\n",
    "from miniai.training import *\n",
    "from miniai.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "898166ae-284b-484c-a828-02a4b648c0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np\n",
    "import pandas as pd,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621f5ab3-e9f2-456b-8feb-16f90d0a0891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9abf128-a98f-45ed-ba4c-8f110dbe8060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_data = Path('../data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d9a2aa-2cf9-4a02-a82e-13e9d8403aa1",
   "metadata": {},
   "source": [
    "## Creating CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ddb143-a730-4e16-9e4c-8a43519fb5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_imgs = x_train.view(-1, 28, 28)\n",
    "xv_imgs = x_valid.view(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18364eb7-2e56-49ce-b16f-7106b5320d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = x_imgs[:16][:, None]\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93a485f-3fb9-4235-b689-3af6396865c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n, m  = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd1794f-4a0a-4379-88a3-4fd5a081e358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0436e586-892e-4ce9-93cf-0e43575d52c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "broken_cnn = nn.Sequential(\n",
    "    nn.Conv2d(1, 30, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(30, 10, kernel_size=3, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364def8f-ca77-4d1e-9d85-e8d7c7ff923d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_cnn(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8678bb1-e555-4989-9e4c-157de043f654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def conv(ni, nf, ks=3, stride=2, act=True):\n",
    "    res = nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n",
    "    if act: res = nn.Sequential(res, nn.ReLU())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e451fc5b-6e7b-41d6-9ee9-1779e56adbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_cnn = nn.Sequential(\n",
    "    conv(1,   4),            # 14x14\n",
    "    conv(4,   8),            # 7x7\n",
    "    conv(8,  16),            # 4x4\n",
    "    conv(16, 16),            # 2x2\n",
    "    conv(16, 10, act=False), # 1x1\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a75a1ce6-b275-4454-b41e-c23ed882b92a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "648cd71f-abdf-4600-9aca-040a4e7f5fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_imgs = x_train.view(-1, 1, 28, 28)\n",
    "xv_imgs = x_valid.view(-1, 1, 28, 28)\n",
    "train_ds, valid_ds = Dataset(x_imgs, y_train), Dataset(xv_imgs, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eaaaad6e-df02-4abc-b0f1-a0136055c74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, torch.Tensor): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k, v in x.items()}\n",
    "    return type(x)(to_device(o, device) for o in x)\n",
    "\n",
    "def collate_device(b): return to_device(default_collate(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8b69027-2413-4584-8d50-62b956f9127f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "bs = 256\n",
    "lr = 0.4\n",
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs, collate_fn=collate_device)\n",
    "opt = optim.SGD(simple_cnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "764c5fd7-4da7-49f0-bf09-0089248be652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.0411722873687745 0.583200000667572\n",
      "1 0.2505298261165619 0.921500000667572\n",
      "2 0.15392718484401702 0.954300000667572\n",
      "3 0.11525343742370606 0.9642999995231628\n",
      "4 0.12151137762069703 0.9636999992370605\n",
      "5 0.16605360834598543 0.947300000667572\n",
      "6 0.10968214440345764 0.9685000007629394\n",
      "7 0.08582237071990967 0.974299999332428\n",
      "8 0.10325235047340393 0.9681999994277954\n",
      "9 0.09661253645420075 0.9737999997138977\n"
     ]
    }
   ],
   "source": [
    "loss, acc = fit(10, simple_cnn.to(def_device), F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b44d467-8fd0-4f9c-996f-b624ad1ead29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.07459476077556611 0.9782999996185303\n",
      "1 0.07574831893444062 0.9788999997138977\n",
      "2 0.08015529987812042 0.9770999996185302\n",
      "3 0.07648587174415589 0.9781999997138977\n",
      "4 0.07417190508842468 0.9782999996185303\n",
      "5 0.07762444217205047 0.9784999996185303\n",
      "6 0.0799566460609436 0.9780999997138977\n",
      "7 0.07907814426422119 0.9790999997138977\n",
      "8 0.07875795543193817 0.9784999996185303\n",
      "9 0.07825491766929626 0.978699999332428\n"
     ]
    }
   ],
   "source": [
    "opt = optim.SGD(simple_cnn.parameters(), lr=lr/4)\n",
    "loss, acc = fit(10, simple_cnn.to(def_device), F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c6d43-6b5a-4555-a788-acdefc45ae0b",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c92a5f9-dc1d-413a-b168-7ede338ae303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620ce54-84aa-46e7-9f8e-61219fc19646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
